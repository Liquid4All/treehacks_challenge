{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ConvModel(torch.nn.Module):\n",
    "    def __init__(self, channels: int, filter_length: int = 3):\n",
    "        \"\"\"\n",
    "        channels: Number of input/output channels.\n",
    "        seq_len: (Optional) Expected sequence length (not strictly required for the model definition).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv1d(\n",
    "            in_channels=channels,\n",
    "            out_channels=channels,\n",
    "            kernel_size=filter_length,\n",
    "            groups=channels,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.left_padding = filter_length - 1\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = torch.nn.functional.pad(x, (self.left_padding, 0))\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 128])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels = 32\n",
    "filter_length = 3\n",
    "x = torch.randn(1, channels, 128)\n",
    "conv = ConvModel(channels, filter_length)\n",
    "x = conv(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (lowered_module_0): LoweredBackendModule()\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    lowered_module_0 = self.lowered_module_0\n",
      "    executorch_call_delegate = torch.ops.higher_order.executorch_call_delegate(lowered_module_0, x);  lowered_module_0 = x = None\n",
      "    getitem = executorch_call_delegate[0];  executorch_call_delegate = None\n",
      "    return (getitem,)\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "from torch.export import export, ExportedProgram\n",
    "from executorch.backends.xnnpack.partition.xnnpack_partitioner import XnnpackPartitioner\n",
    "from executorch.exir import EdgeProgramManager, ExecutorchProgramManager, to_edge_transform_and_lower\n",
    "from executorch.exir.backend.backend_api import to_backend\n",
    "\n",
    "SEQ_LEN = 256\n",
    "FILTER_LENGTH = 3\n",
    "CHANNELS = 4\n",
    "model = ConvModel(channels=CHANNELS, filter_length=FILTER_LENGTH)\n",
    "example_input = torch.randn(1, CHANNELS, SEQ_LEN)\n",
    "\n",
    "exported_program: ExportedProgram = export(model, (example_input,))\n",
    "edge_program: EdgeProgramManager = to_edge_transform_and_lower(exported_program, partitioner=[XnnpackPartitioner()])\n",
    "print(edge_program.exported_program().graph_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total delegated subgraphs: 1\n",
      "Number of delegated nodes: 2\n",
      "Number of non-delegated nodes: 1\n",
      "\n",
      "╒════╤══════════════════════════════╤═══════════════════════════════════╤═══════════════════════════════════════╕\n",
      "│    │ op_type                      │   occurrences_in_delegated_graphs │   occurrences_in_non_delegated_graphs │\n",
      "╞════╪══════════════════════════════╪═══════════════════════════════════╪═══════════════════════════════════════╡\n",
      "│  0 │ aten_constant_pad_nd_default │                                 1 │                                     0 │\n",
      "├────┼──────────────────────────────┼───────────────────────────────────┼───────────────────────────────────────┤\n",
      "│  1 │ aten_convolution_default     │                                 1 │                                     0 │\n",
      "├────┼──────────────────────────────┼───────────────────────────────────┼───────────────────────────────────────┤\n",
      "│  2 │ getitem                      │                                 0 │                                     1 │\n",
      "├────┼──────────────────────────────┼───────────────────────────────────┼───────────────────────────────────────┤\n",
      "│  3 │ Total                        │                                 2 │                                     1 │\n",
      "╘════╧══════════════════════════════╧═══════════════════════════════════╧═══════════════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "from executorch.devtools.backend_debug import get_delegation_info\n",
    "from tabulate import tabulate\n",
    "graph_module = edge_program.exported_program().graph_module\n",
    "delegation_info = get_delegation_info(graph_module)\n",
    "print(delegation_info.get_summary())\n",
    "df = delegation_info.get_operator_delegation_dataframe()\n",
    "print(tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
